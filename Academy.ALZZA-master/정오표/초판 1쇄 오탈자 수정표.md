# 초판 1쇄 오탈자 수정표

## 22쪽 8.8.5절 목차
발견자: 윤덕호<br/>
등록일: 2019.10.21<br/>
내용: 파라미터 갱신 함수 재정의 → 파라미터 갱신 메서드 재정의<br/>
반영: 미반영

## 25쪽 10.7.4절 목차
발견자: 윤덕호<br/>
등록일: 2019.11.1<br/>
내용: 파라미터 순전파 메서드 → 순전파 메서드<br/>
반영: 미반영

## 25쪽 10.7.5절 목차
발견자: 윤덕호<br/>
등록일: 2019.11.1<br/>
내용: 파라미터 역전파 메서드 → 역전파 메서드<br/>
반영: 미반영
## 39쪽 6째 줄
발견자: 코난아카데미<br/>
등록일: 2019.8.5<br/>
내용: 일부 테이터의 경우 → 일부 데이터의 경우<br/>
반영: 초판 2쇄

## 40쪽 그림
발견자: 박미선<br/>
등록일: 2019.7.17<br/>
내용: 축삭 (2번 나타난 것 중 왼쪽) → 세포체<br/>
내용: 가지돌기 → 축삭말단<br/>
반영: 초판 2쇄

## 41쪽 9째줄
발견자: 박미선<br/>
등록일: 2019.7.17<br/>
내용: 무수히 붙은 가지돌기를 → 무수히 붙은 축삭말단을<br/>
반영: 초판 2쇄

## 42쪽 그림 아래 4째줄
발견자: 박미선<br/>
등록일: 2019.7.17<br/>
내용: 각 수상돌기로부터 들어오는 → 각 가지돌기로부터 들어오는<br/>
반영: 초판 2쇄

## 51쪽 마지막줄
발견자: 윤덕호<br/>
등록일: 2019.8.30<br/>
내용: 3장에서 살펴본다 → 4장에서 살펴본다<br/>
반영: 초판 2쇄

## 55쪽 그림
발견자: 윤영섬<br/>
등록일: 2019.7.13<br/>
내용: 너 올해 몇 살이나? → 너 올해 몇 살이니?<br/>
반영: 초판 2쇄

## 61쪽 2째 줄
발견자: 박범진<br/>
등록일: 2019.7.28<br/>
내용: 몸시 어렵지만 → 몹시 어렵지만<br/>
반영: 초판 2쇄

## 70쪽 그림
발견자: 양승현<br/>
등록일: 2019.8.6<br/>
내용: abablone_exec() → abalone_exec()<br/>
반영: 초판 2쇄

## 71쪽 1.10.3 코드 아래 설명문 첫 줄
발견자: 박범진<br/>
등록일: 2019.7.28<br/>
내용: load_ablone_dataset() → load_abalone_dataset()<br/>
반영: 초판 2쇄

## 78쪽 3째 줄
발견자: 류기윤<br/>
등록일: 2019.8.22<br/>
내용: 순전파 첫 단계인 backprop_neuralnet() 함수가 → backprop_neuralnet() 함수가<br/>
반영: 초판 2쇄

## 78쪽 1.10.9절 첫 줄
발견자: 이인혁<br/>
등록일: 2019.8.29<br/>
내용: 신경만 → 신경망<br/>
반영: 초판 2쇄

## 80쪽 첫번째 글상자 본문 9째 줄
발견자: 권기범<br/>
등록일: 2019.10.15<br/>
내용: GnjXnk → GmjXmk<br/>
반영: 미반영

## 94쪽 그림 오른쪽 맨 아래 말풍선
발견자: 박범진<br/>
등록일: 2019.7.31<br/>
내용: 0.270 → = 0.270<br/>
반영: 초판 2쇄

## 96쪽 글상자 4째 줄
발견자: 이상호<br/>
등록일: 2019.8.8<br/>
내용: g(x)=1+e<sup>x</sup> → g(x)=1+e<sup>-x</sup><br/>
반영: 초판 2쇄

## 2.6절 전체 (101쪽~102쪽 상단)
발견자: 윤덕호<br/>
등록일: 2019.9.5<br/>
내용: 전체적으로 P와 Q를 맞바꾸어야 99쪽 하단의 H(P,Q) 정의 내용과 혼동되지 않음<br/>
반영: 초판 2쇄

## 2.6절 전체 (101쪽~102쪽 상단)
발견자: 윤덕호<br/>
등록일: 2019.9.5<br/>
내용: 조건부 확률 분포 P를 → 조건부 확률 분포로 Q를 (101쪽 18째 줄)<br/>
반영: 초판 2쇄에 '조건부 확률 분포로 P를'로 잘못 반영됨<br/>

## 104쪽 글상자 안의 수식들
발견자: 류기윤<br/>
등록일: 2019.8.22<br/>
내용: 수식 두 번째 줄부터 4번째 줄까지 사이에 나타난 5개의 e<sup>-z</sup> → e<sup>-x</sup><br/>
반영: 초판 2쇄

## 116쪽 7째 줄
발견자: 성주석<br/>
등록일: 2019.12.12<br/>
내용: 재현율이 낮아지고 거짓이라고 함부로 답하면 정밀도가 추락한다 → 정밀도가 낮아지고 거짓이라고 함부로 답하면 재현율이 추락한다<br/>
반영: 미반영

## 119-120쪽 2.11.4절 코드상자 8~9째 줄, 12째 줄
발견자: 정소라<br/>
등록일: 2019.8.14<br/>
내용취지: 실행상에는 차이가 없으나 117쪽의 설명과 부합되기 위해서는 변수명 수정이 필요함<br/>
내용: fn = np.sum(np.logical_and(est_no, ans_yes)) → fn = np.sum(np.logical_and(est_no, ans_no))<br/>
내용: tn = np.sum(np.logical_and(est_no, ans_no)) → fn = np.sum(np.logical_and(est_no, ans_yes))<br/>
내용: recall = safe_div(tp, tp+fn) → recall = safe_div(tp, tp+tn)<br/>
반영: 초판 2쇄

## 123쪽 본문 6~9째 줄
발견자: 김정태<br/>
등록일: 2019.8.13<br/>
내용: 데이터셋에서 데이터 간의 균형이 중요하다는 점과 정확도가 아닌 다른 성능 지표를 활용하는 것이 매우 유용함을 알 수 있다. 앞으로 소개할 여러 데이터셋이나 신경망에서 이 두 문제를 다시 다루지는 않겠지만 신경망을 실제 문제에 적용할 때 이런 점을 함께 고려하면 많은 도움이 될 것이다.<br/>
수정: 끝으로 본 단원에 남은 한 가지 문제를 지적하자. 2.11.3절에서 부족한 펄서 데이터들을 복사해 별 데이터와 같은 개수로 채우고 나면 같은 내용의 데이터가 학습용 데이터와 평가용 데이터 양쪽 모두 이용될 수 있다. 이는 8장에서 소개할 과적합 현상을 초래하여 올바른 학습을 방해하는 원인이 될 수 있다. 아쉽지만 이 문제의 해결은 독자 각자에게 맡긴다.<br/>
반영: 초판 2쇄

## 144쪽 8째 줄
발견자: 양승현<br/>
등록일: 2019.8.27<br/>
내용: 10<sup>-10</sup>을 사용한다.<br/>
수정: 10<sup>-10</sup>을 사용한다. 한편 labels가 원-핫 벡터라는 전제를 두면 ❹의 계산식을 정답 위치의 로그 값만 계산하는 형태로 간단하게 고칠 수 있다. 하지만 labels 형태에 원-핫 벡터라는 제약이 필요하므로 여기에서는 이용하지 않았다.<br/>
반영: 초판 2쇄

## 162쪽 코드상자 9째 줄
발견자: 이인혁<br/>
등록일: 2019.9.17<br/>
내용: def backprop_neuralnet(G_output, x, learning_rate) → def backprop_neuralnet(G_output, x)<br/>
반영: 초판 2쇄

## 191쪽 코드상자 아래 본문 첫째 줄
발견자: 이인혁<br/>
등록일: 2019.9.24<br/>
내용: exec_all() 메서드가  → 객체 초기화 메서드 __init__()가<br/>
반영: 미반영

## 191쪽 코드상자 아래 본문 3째 줄
발견자: 이인혁<br/>
등록일: 2019.9.24<br/>
내용: init_model 함수와 → init_model_hiddens() 함수와<br/>
반영: 미반영

## 199쪽 본문 첫 줄
발견자: 이인혁<br/>
등록일: 2019.10.16<br/>
내용: 구하며 호출한다 → 구하기 위해 호출한다<br/>
반영: 미반영

## 199쪽 본문 세번째 문단 2째 줄
발견자: 이인혁<br/>
등록일: 2019.10.16<br/>
내용: 보고한다 → 구해 처리 결과에 반영한다<br/>
반영: 미반영

## 208쪽 본문 5째 줄
발견자: 이인혁<br/>
등록일: 2019.10.16<br/>
내용: 1.10.9절 '단층 퍼셉트론에 대한 → 1.10.10절 '후처리 과정에 대한<br/>
반영: 미반영

## 209쪽 본문 2째 줄
발견자: 이인혁<br/>
등록일: 2019.10.16<br/>
내용: 1.10.9절 '단층 퍼셉트론에 대한 → 1.10.10절 '후처리 과정에 대한<br/>
반영: 미반영

## 230쪽 본문 1째 줄
발견자: 이인혁<br/>
등록일: 2019.10.16<br/>
내용: rsgression → regression<br/>
반영: 미반영

## 233쪽 1째 줄
발견자: 윤덕호<br/>
등록일: 2019.9.28<br/>
내용: 소단원 분리 필요<br/>
반영: 미반영

## 234쪽 본문 5째 줄
발견자: 윤덕호<br/>
등록일: 2019.9.28<br/>
내용: 소단원 분리 필요<br/>
반영: 미반영

## 240쪽 11째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.2<br/>
내용: 이번 절에서 → 이번 장에서<br/>
반영: 미반영

## 242쪽 6.3절 전체
발견자: 윤덕호<br/>
등록일: 2019.10.2<br/>
문제: 전체적으로 MlpModel을 그대로 이용하면 되는 것으로 설명되고 있어서 AdamModel 클래스를 새로 선언하는 6.5절 내용과 혼동을 야기함<br/>
수정방향: 오해를 막는 수준에서 단원 제목 및 본문 내용을 수정할 예정임<br/>
반영: 미반영

## 242쪽 6.3절 본분 5째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.2<br/>
내용: 3.2절 → 5장<br/>
반영: 미반영

## 246쪽 6.5.5절 제목
발견자: 윤덕호<br/>
등록일: 2019.10.4<br/>
내용: 두 가지 파라미터 수정 메서드 정의 → 아담 알고리즘 적용 메서드 정의<br/>
반영: 미반영

## 252쪽 본문 6째 줄
발견자: 이인혁<br/>
등록일: 2019.10.16<br/>
내용: 물론 \[3, 31\]이다 → 물론 \[3\]이다<br/>
반영: 미반영

## 275쪽 수식 아래 8째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.11<br/>
내용: 대푯값 간출은 → 대푯값 산출은<br/>
반영: 미반영

## 277쪽 3번째 수식 오른쪽
발견자: 서종우<br/>
등록일: 2019.8.7<br/>
내용: dy<sub>k,i,j,ym</sub>x<sub>k,r-i+bh,c-j+bw,xm</sub> → dy<sub>k,i,j,ym</sub>x<sub>k,r+i-bh,c+j-bw,xm</sub><br/>
반영: 초판 2쇄

## 293쪽 본문 1째 줄
발견자: 이인혁<br/>
등록일: 2019.10.16<br/>
내용: ksize와 ychn 키값을 → 'ksize'와 'chn' 키값을<br/>
반영: 미반영

## 328쪽 3째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.16<br/>
내용: 실제 업무, 즉 정규화 단계에서 → 실제 업무, 즉 일반화 단계에서<br/>
반영: 미반영

## 328쪽 4째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.16<br/>
내용: 오히려 정규화 단계의 성능을 → 오히려 일반화 단계에서의 성능을<br/>
반영: 미반영

## 329쪽 8.1절 마지막 두 줄
발견자: 윤덕호<br/>
등록일: 2019.10.16<br/>
내용: 참고로 정규화 기법은 정규화 단계에서의 → 참고로 정규화 기법은 일반화 단계에서의<br/>
내용: 평가 단계가 정규화 단계에 대한 모의실험 → 평가 단계가 일반화 단계에 대한 모의실험<br/>
반영: 미반영

## 335쪽 2째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.18<br/>
내용: deterministic Boltzmann machine → deep Boltzmann machine<br/>
반영: 미반영

## 336쪽 7째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.18<br/>
내용: 비용 기울기가 급격히 소멸하거나 폭주하면서 → 손실 기울기가 급격히 소멸하거나 폭주하면서<br/>
반영: 미반영

## 336쪽 9째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.18<br/>
내용: 가중치 파라미터의 비용 기울기를 → 가중치 파라미터의 손실 기울기를<br/>
반영: 미반영

## 336쪽 18째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.18<br/>
내용: 미니배치 데이터가 \[m,n\] 형태의 입력이 주어졌을 때 → 미니배치 데이터가 \[m,n\] 형태의 입력으로 주어졌을 때<br/>
반영: 미반영

## 344쪽 8.8.5절 목차
발견자: 윤덕호<br/>
등록일: 2019.10.21<br/>
내용: 파라미터 갱신 함수 재정의 → 파라미터 갱신 메서드 재정의<br/>
반영: 미반영

## 345쪽 코드 8~13째 줄
발견자: 윤덕호<br/>
등록일: 2019.9.9<br/>
내용: 이어서 순전파 처리를 담당하는 forward_dropout_layer() 메서드에서는 ➍에서 np.random.binomial() 함수를 이용하여 pm['keep_prob']의 확률로 1, 나머지 확률로 0의 난수들을 x와 같은 형태로 발생시키고 ➎에서 이렇게 생성된 dmask를 x에 곱해 일부 원소들을 0으로 만들어 이후의 의사 결정 과정에서 배제하도록 한다. 이 처리는 학습 단계에서만 수행되어야 하므로 is_training 플래그를 검사하며, pm['keep_prob']로 나누어 기댓값을 유지시키고 dmask를 역전파용 보조 정보로 전달한다.<br/>
수정: ➍의 순전파 처리에서는 pm['keep_prob']의 확률로 1, 나머지를 0으로 x와 같은 형태의 난수들을 발생시켜 드롭아웃 마스크를 만들고 ➎에서 이 마스크를 x에 곱해 일부 원소들을 0으로 만들어 이후의 처리 과정에서 배제시킨다. 그런데 ➍의 마스크는 x.shape 대신 x.shape[1:] 형태로 지정해 미니배치 단위로 일괄 처리하는 편이 더욱 효과적인데 이 점은 각자 확인해보기로 하자. 한편 드롭아웃 처리는 학습 단계에서만 수행되어야 하므로 is_training 플래그를 검사하며, pm['keep_prob']로 나누어 기댓값을 유지시킨다.<br/><br/>
* x.shape 대신 x.shape[1:] 형태로 지정하는 것이 올바른 드롭아웃 사용법이다. 하지만 이 부분을 수정할 경우 드롭아웃 실험부터의 모든 실험 결과가 교재로 달라지므로 개정판이 나올 때까지 코드 내용은 x.shape 형태를 이용하는 것으로 유지하기로 한다. x.shape[1:] 형태를 이용하는 실험은 각자 수행해 보기로 하자.<br>
반영: 초판 2쇄

## 351쪽 8.9.2 코드블록 위 줄
발견자: 윤덕호<br/>
등록일: 2019.10.14<br/>
내용: chap07/cnn_basic_test.ipynb → chap08/cnn_reg_test.ipynb<br/>
반영: 미반영

## 368쪽 9.2.1절 본분 1째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.4<br/>
내용: 레스넷 개발은 → 레스넷 모델은<br/>
반영: 미반영

## 368쪽 9.2.1절 본분 2째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.4<br/>
내용: 레스넷 모듈로 → 레스넷 모델로<br/>
반영: 미반영

## 394쪽 5째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.16<br/>
내용: 앞서 소개한 반복 구조 앞에서 본 아래의 반복구조를 → 앞서 소개한 아래의 반복 구조를<br/>
반영: 미반영

## 394쪽 마지막 예제 코드 첫째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.16<br/>
내용: CnnExtModel.set_macro('residual_chain', → CnnExtModel.set_macro('residual',<br/>
반영: 미반영

## 456쪽 10.5절 본문 첫째 줄
발견자: 윤덕호<br/>
등록일: 2019.10.24<br/>
내용: 이 절에서는 → 이 장에서는<br/>
반영: 미반영

## 467쪽 10.7.4절 제목
발견자: 윤덕호<br/>
등록일: 2019.11.1<br/>
내용: 파라미터 순전파 메서드 → 순전파 메서드<br/>
반영: 미반영

## 469쪽 10.7.5절 제목
발견자: 윤덕호<br/>
등록일: 2019.11.1<br/>
내용: 파라미터 역전파 메서드 → 역전파 메서드<br/>
반영: 미반영

## 496쪽 마지막 줄 수식
발견자: 윤덕호<br/>
등록일: 2019.11.6<br/>
내용: 1−2σ(2x) → 1−2σ(-2x)<br/>
반영: 미반영

## 500쪽 11.6절 본문 6째 줄
발견자: 윤덕호<br/>
등록일: 2019.11.7<br/>
내용: 4,4100Hz 주기로 → 44,100Hz 주기로<br/>
반영: 미반영

## 548쪽 8째 줄
발견자: 서종우<br/>
등록일: 2019.9.17<br/>
내용: \[90, 120, 30\] → \[90, 120, 3\]<br/>
반영: 초판 2쇄

## 548쪽 9째 줄
발견자: 서종우<br/>
등록일: 2019.9.17<br/>
내용: \[90, 120, 30\] → \[90, 120, 3\]<br/>
반영: 초판 2쇄

## 572쪽 7째 줄
발견자: 윤덕호<br/>
등록일: 2019.11.20<br/>
내용: 정규화 시점부터는 → 일반화 시점부터는<br/>
반영: 미반영

## 666쪽 15.5.4절 첫째 줄
발견자: 윤덕호<br/>
등록일: 2019.12.16<br/>
내용: 판변기와 생성기의 → 판별기와 생성기의<br/>
반영: 미반영

## 692쪽 오른쪽 하단
발견자: 윤덕호<br/>
등록일: 2019.10.4<br/>
내용: cnn_basic_forward_avg_layer 308 → (행 삭제)<br/>
반영: 미반영
